{
 "cells": [
  {
   "cell_type": "code",
   "id": "3841a318",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:34:38.006744Z",
     "start_time": "2025-05-29T09:34:34.508682Z"
    }
   },
   "source": [
    "%pip install transformers"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\loris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\loris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\loris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.31.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\loris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\loris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\loris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\loris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\loris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\loris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\loris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\loris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\loris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\loris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\loris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\loris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\loris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\loris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\loris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "id": "6fcb0697",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:34:38.025267Z",
     "start_time": "2025-05-29T09:34:38.009272Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "import random\n",
    "#from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import transformers\n",
    "from transformers import BertForSequenceClassification, BertConfig,BertTokenizer,get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 94
  },
  {
   "cell_type": "markdown",
   "id": "85f67a54",
   "metadata": {},
   "source": [
    "Estrazione file"
   ]
  },
  {
   "cell_type": "code",
   "id": "ed18caa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:34:40.025167Z",
     "start_time": "2025-05-29T09:34:38.029483Z"
    }
   },
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "zip_path = 'sentimentAnalysis.zip'\n",
    "\n",
    "with zipfile.ZipFile(zip_path) as z:\n",
    "    with z.open('netflix_reviews.csv') as csv:\n",
    "        df = pd.read_csv(csv)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (136804, 8)\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "id": "2fb801d4",
   "metadata": {},
   "source": [
    "Prendiamo un sample di dati per non avere difficoltà con la memoria"
   ]
  },
  {
   "cell_type": "code",
   "id": "a30551db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:34:40.057825Z",
     "start_time": "2025-05-29T09:34:40.034182Z"
    }
   },
   "source": [
    "\n",
    "subset = df[['content', 'score']]\n",
    "train_data = subset.iloc[:1000]        # Righe da 0 a 9999 (prime 10.000)\n",
    "test_data = subset.iloc[1000:1200]    # Righe da 10000 a 11999 (dal 10.001° al 12.000°)\n",
    "subset.head(5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             content  score\n",
       "0               what happen netflix??? i can't watch      1\n",
       "1                               Good better and best      5\n",
       "2                                      fix bug pls !      1\n",
       "3                     I can't cancel my subscription      1\n",
       "4  this app is almost unusable on my phone. the b...      1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what happen netflix??? i can't watch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good better and best</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fix bug pls !</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can't cancel my subscription</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this app is almost unusable on my phone. the b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "cell_type": "markdown",
   "id": "a9800f1b6618a11f",
   "metadata": {},
   "source": [
    "## Fase di ETL\n",
    "Iniziamo ripulendo il dataset da tutti i caratteri speciali, emoji e tag html"
   ]
  },
  {
   "cell_type": "code",
   "id": "d86c22d1048c6423",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:34:40.110728Z",
     "start_time": "2025-05-29T09:34:40.060383Z"
    }
   },
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    if text is None:\n",
    "        return None\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z?.!,]+\",\" \", text)\n",
    "    text = re.sub(r\"http\\S+\", \"\",text) #Removing URLs \n",
    "    #text = re.sub(r\"http\", \"\",text)\n",
    "    \n",
    "    html=re.compile(r'<.*?>') \n",
    "    \n",
    "    text = html.sub(r'',text) #Removing html tags\n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n",
    "    for p in punctuations:\n",
    "        text = text.replace(p,'') #Removing punctuations\n",
    "        \n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    \n",
    "    text = \" \".join(text) #removing stopwords\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text) #Removing emojis\n",
    "    \n",
    "    return text"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\loris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "id": "cf57059f29a3da49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:34:40.965672Z",
     "start_time": "2025-05-29T09:34:40.117734Z"
    }
   },
   "source": [
    "train_data['content'] = train_data['content'].apply(lambda x: clean_text(x) if isinstance(x, str) else '')\n",
    "test_data['content'] = test_data['content'].apply(lambda x: clean_text(x) if isinstance(x, str) else '')\n",
    "train_data = train_data[train_data['content'].str.strip() != ''].reset_index(drop=True)\n",
    "test_data = test_data[test_data['content'].str.strip() != ''].reset_index(drop=True)\n",
    "\n",
    "index = 0\n",
    "reviews = train_data.content.values\n",
    "abs = train_data.score.values\n",
    "\n",
    "labels = []\n",
    "for i in abs:\n",
    "    if int(i)== 1:\n",
    "        labels.append(0) # classe 0 per giudizi negativi\n",
    "    elif int(i)<= 3:\n",
    "        labels.append(1) # classe 1 per giudizi neutri\n",
    "    else:\n",
    "        labels.append(2) # classe 2 per giudizi positivi\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "table = np.array([tokenizer.tokenize(reviews[index]), \n",
    "                    tokenizer.convert_tokens_to_ids(tokenizer.tokenize(reviews[index]))]).T\n",
    "print(tabulate(table,headers = ['Tokens', 'Token IDs'],tablefmt = 'fancy_grid'))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loris\\AppData\\Local\\Temp\\ipykernel_11916\\582491485.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['content'] = train_data['content'].apply(lambda x: clean_text(x) if isinstance(x, str) else '')\n",
      "C:\\Users\\loris\\AppData\\Local\\Temp\\ipykernel_11916\\582491485.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['content'] = test_data['content'].apply(lambda x: clean_text(x) if isinstance(x, str) else '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════╤═════════════╕\n",
      "│ Tokens   │   Token IDs │\n",
      "╞══════════╪═════════════╡\n",
      "│ happen   │        4148 │\n",
      "├──────────┼─────────────┤\n",
      "│ netflix  │       20907 │\n",
      "├──────────┼─────────────┤\n",
      "│ watch    │        3422 │\n",
      "╘══════════╧═════════════╛\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "id": "a02f21bdc2644db6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:34:41.255744Z",
     "start_time": "2025-05-29T09:34:40.968549Z"
    }
   },
   "source": [
    "max_len = 0\n",
    "mean = 0\n",
    "# For every sentence...\n",
    "for sent in reviews:\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True, max_length=tokenizer.model_max_length, truncation=True)\n",
    "    # Update the maximum sentence length.\n",
    "    if len(input_ids) > max_len:\n",
    "        max_len = len(input_ids)\n",
    "    mean = mean + len(input_ids)\n",
    "mean /= len(reviews)\n",
    "print('Max sentence length: ', max_len, ' | Average sentence length: ', mean)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  74  | Average sentence length:  12.01223241590214\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "id": "26b130f81d4653",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:34:41.857919Z",
     "start_time": "2025-05-29T09:34:41.260645Z"
    }
   },
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every tweet...\n",
    "for sent in reviews:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        truncation=True,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2700: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "id": "5fb7bbeae04a353",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:34:41.872630Z",
     "start_time": "2025-05-29T09:34:41.863943Z"
    }
   },
   "source": [
    "i=random.randint(0,len(reviews)-1)\n",
    "print('Original: ', reviews[i])\n",
    "print('Input IDs:', input_ids[i])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  know compatibility tvs tv use netflix always watch netflix make sure paid monthly already uninstalled tv\n",
      "Input IDs: tensor([  101,  2113, 21778,  2694,  2015,  2694,  2224, 20907,  2467,  3422,\n",
      "        20907,  2191,  2469,  3825,  7058,  2525,  4895,  7076,  9080,  3709,\n",
      "         2694,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "id": "222a6fbf47547cf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:34:41.914162Z",
     "start_time": "2025-05-29T09:34:41.875300Z"
    }
   },
   "source": [
    "def print_rand_sentence_encoding():\n",
    "  '''Displays tokens, token IDs and attention mask of a random text sample'''\n",
    "  index = random.randint(0, len(reviews) - 1)\n",
    "  tokens = tokenizer.tokenize(tokenizer.decode(input_ids[index]))\n",
    "  token_ids = [i.numpy() for i in input_ids[index]]\n",
    "  attention = [i.numpy() for i in attention_masks[index]]\n",
    "\n",
    "  table = np.array([tokens, token_ids, attention]).T\n",
    "  print(reviews[index])\n",
    "  print(tabulate(table, \n",
    "                 headers = ['Tokens', 'Token IDs', 'Attention Mask'],\n",
    "                 tablefmt = 'fancy_grid'))\n",
    "\n",
    "print_rand_sentence_encoding()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app dimming increasing brightness own, google pixel\n",
      "╒════════════╤═════════════╤══════════════════╕\n",
      "│ Tokens     │   Token IDs │   Attention Mask │\n",
      "╞════════════╪═════════════╪══════════════════╡\n",
      "│ [CLS]      │         101 │                1 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ app        │       10439 │                1 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ dim        │       11737 │                1 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ ##ming     │        6562 │                1 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ increasing │        4852 │                1 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ brightness │       18295 │                1 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ own        │        2219 │                1 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ ,          │        1010 │                1 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ google     │        8224 │                1 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ pixel      │       22138 │                1 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [SEP]      │         102 │                1 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "├────────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]      │           0 │                0 │\n",
      "╘════════════╧═════════════╧══════════════════╛\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "id": "996b9040c3e47ae0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:34:41.925679Z",
     "start_time": "2025-05-29T09:34:41.915173Z"
    }
   },
   "source": [
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.8 * len(dataset))\n",
    "#val_size = int(0.2 * len(dataset))\n",
    "val_size = len(dataset)  - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  784 training samples\n",
      "  197 validation samples\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "cell_type": "code",
   "id": "d7dd9b3b38338607",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:34:41.938700Z",
     "start_time": "2025-05-29T09:34:41.929694Z"
    }
   },
   "source": [
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": 104
  },
  {
   "cell_type": "code",
   "id": "183150f57435747c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:34:41.951670Z",
     "start_time": "2025-05-29T09:34:41.941226Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "def b_tp(preds, labels):\n",
    "  '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n",
    "  return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_fp(preds, labels):\n",
    "  '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n",
    "  return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_tn(preds, labels):\n",
    "  '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n",
    "  return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_fn(preds, labels):\n",
    "  '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n",
    "  return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def multi_class_metrics(preds, labels):\n",
    "    preds = np.argmax(preds, axis=1).flatten()\n",
    "    labels = labels.flatten()\n",
    "    \n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='macro')  # puoi usare 'weighted'\n",
    "    recall = recall_score(labels, preds, average='macro')\n",
    "    \n",
    "    return acc, precision, recall"
   ],
   "outputs": [],
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "id": "335bd2004bc9d617",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:34:42.780969Z",
     "start_time": "2025-05-29T09:34:41.954679Z"
    }
   },
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# if device == \"cuda:0\":\n",
    "# # Tell pytorch to run this model on the GPU.\n",
    "#     model = model.cuda()\n",
    "model = model.to(device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "cell_type": "code",
   "id": "1c57acd68bf57f34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:34:42.788245Z",
     "start_time": "2025-05-29T09:34:42.782978Z"
    }
   },
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ],
   "outputs": [],
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "id": "fd753f9887878a47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:34:42.797322Z",
     "start_time": "2025-05-29T09:34:42.790255Z"
    }
   },
   "source": [
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ],
   "outputs": [],
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "id": "6e0c26b46a67c0ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:34:42.804202Z",
     "start_time": "2025-05-29T09:34:42.799334Z"
    }
   },
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ],
   "outputs": [],
   "execution_count": 109
  },
  {
   "cell_type": "code",
   "id": "dd9e3678f2a79e94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:34:42.811212Z",
     "start_time": "2025-05-29T09:34:42.806210Z"
    }
   },
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ],
   "outputs": [],
   "execution_count": 110
  },
  {
   "cell_type": "code",
   "id": "48dcb0a1f97007d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:43:41.263600Z",
     "start_time": "2025-05-29T09:34:42.813732Z"
    }
   },
   "source": [
    "epochs = 4\n",
    "\n",
    "for _ in trange(epochs, desc = 'Epoch'):\n",
    "    \n",
    "    # ========== Training ==========\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Tracking variables\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        train_output = model(b_input_ids, \n",
    "                             token_type_ids = None, \n",
    "                             attention_mask = b_input_mask, \n",
    "                             labels = b_labels)\n",
    "        # Backward pass\n",
    "        train_output.loss.backward()\n",
    "        optimizer.step()\n",
    "        # Update tracking variables\n",
    "        tr_loss += train_output.loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    # ========== Validation ==========\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    val_accuracy = []\n",
    "    val_precision = []\n",
    "    val_recall = []\n",
    "    val_specificity = []\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "          # Forward pass\n",
    "          eval_output = model(b_input_ids, \n",
    "                              token_type_ids = None, \n",
    "                              attention_mask = b_input_mask)\n",
    "        logits = eval_output.logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate validation metrics\n",
    "        b_accuracy, b_precision, b_recall = multi_class_metrics(logits, label_ids)\n",
    "        val_accuracy.append(b_accuracy)\n",
    "        # Update precision only when (tp + fp) !=0; ignore nan\n",
    "        if b_precision != 'nan': val_precision.append(b_precision)\n",
    "        # Update recall only when (tp + fn) !=0; ignore nan\n",
    "        if b_recall != 'nan': val_recall.append(b_recall)\n",
    "\n",
    "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
    "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
    "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
    "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]C:\\Users\\loris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\loris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\loris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\loris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\loris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Epoch:  25%|██▌       | 1/4 [02:58<08:55, 178.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Train loss: 0.8904\n",
      "\t - Validation Accuracy: 0.6589\n",
      "\t - Validation Precision: 0.4400\n",
      "\t - Validation Recall: 0.4948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\loris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\loris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\loris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Epoch:  50%|█████     | 2/4 [05:32<05:28, 164.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Train loss: 0.6860\n",
      "\t - Validation Accuracy: 0.7348\n",
      "\t - Validation Precision: 0.5455\n",
      "\t - Validation Recall: 0.5676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\loris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\loris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\loris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\loris\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Epoch:  75%|███████▌  | 3/4 [08:09<02:40, 160.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Train loss: 0.5199\n",
      "\t - Validation Accuracy: 0.7304\n",
      "\t - Validation Precision: 0.4953\n",
      "\t - Validation Recall: 0.5509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████▌  | 3/4 [08:58<02:59, 179.44s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[111]\u001B[39m\u001B[32m, line 24\u001B[39m\n\u001B[32m     19\u001B[39m train_output = model(b_input_ids, \n\u001B[32m     20\u001B[39m                      token_type_ids = \u001B[38;5;28;01mNone\u001B[39;00m, \n\u001B[32m     21\u001B[39m                      attention_mask = b_input_mask, \n\u001B[32m     22\u001B[39m                      labels = b_labels)\n\u001B[32m     23\u001B[39m \u001B[38;5;66;03m# Backward pass\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m \u001B[43mtrain_output\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     25\u001B[39m optimizer.step()\n\u001B[32m     26\u001B[39m \u001B[38;5;66;03m# Update tracking variables\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:581\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    571\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    572\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    573\u001B[39m         Tensor.backward,\n\u001B[32m    574\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    579\u001B[39m         inputs=inputs,\n\u001B[32m    580\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m581\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    582\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    583\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    342\u001B[39m     retain_graph = create_graph\n\u001B[32m    344\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    345\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    346\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m347\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    348\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    349\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    350\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    351\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    352\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    353\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    823\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    824\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m825\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    826\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    827\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    828\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    829\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "id": "6f8da8fb2db8dd98",
   "metadata": {},
   "source": [
    "test_input_ids = []\n",
    "test_attention_masks = []\n",
    "test_tweets=['WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.']\n",
    "for tweet in test_tweets:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        tweet,                     \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = max_len,         \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "    test_input_ids.append(encoded_dict['input_ids'])\n",
    "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
    "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
    "test_attention_masks = torch.cat(test_attention_masks, dim=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "24f5fb3ef617a45a",
   "metadata": {},
   "source": [
    "predictions = []\n",
    "for batch in test_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        with torch.no_grad():        \n",
    "            output= model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask)\n",
    "            logits = output.logits\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "            \n",
    "            predictions.extend(list(pred_flat))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "17f8e5c1af016d09",
   "metadata": {},
   "source": [
    "df_output = pd.DataFrame()\n",
    "df_output['tweets']=test_tweets\n",
    "df_output['label'] =predictions\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7d6d56afad0f182c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T09:43:41.272608Z",
     "start_time": "2025-05-29T09:43:41.272608Z"
    }
   },
   "source": [
    "df_output.head()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
