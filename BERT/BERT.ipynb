{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3841a318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\alep9\\anaconda3\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\alep9\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\alep9\\anaconda3\\lib\\site-packages (from transformers) (0.31.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\alep9\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alep9\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\alep9\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\alep9\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\alep9\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\alep9\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\alep9\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\alep9\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\alep9\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\alep9\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\alep9\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alep9\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alep9\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alep9\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alep9\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fcb0697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alep9\\OneDrive\\Desktop\\UNIVERSITA\\Data Science\\Progetti\\Data-Science\\BERT\\.conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "import random\n",
    "#from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import transformers\n",
    "from transformers import BertForSequenceClassification, BertConfig,BertTokenizer,get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f67a54",
   "metadata": {},
   "source": [
    "Estrazione file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed18caa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (25000, 2)\n",
      "Test shape: (25000, 2)\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "zip_path = 'IMDB.zip'\n",
    "\n",
    "with zipfile.ZipFile(zip_path) as z:\n",
    "    with z.open('train.csv') as f_train, z.open('test.csv') as f_test:\n",
    "        train_df = pd.read_csv(f_train)\n",
    "        test_df = pd.read_csv(f_test)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb801d4",
   "metadata": {},
   "source": [
    "Prendiamo un sample di dati per non avere difficolt√† con la memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a30551db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_df[:3000]\n",
    "test_data = test_df[:750]\n",
    "\n",
    "train_data = train_data.to_dict(orient='records')\n",
    "test_data = test_data.to_dict(orient='records')\n",
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c58cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 3000, 750, 750)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts, train_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), train_data)))\n",
    "test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), test_data)))\n",
    "\n",
    "len(train_texts), len(train_labels), len(test_texts), len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5df69a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The saddest thing about this \"tribute\" is that almost all the singers (including the otherwise incredibly talented Nick Cave) seem to have missed the whole point where Cohen\\'s intensity lies: by delivering his lines in an almost tuneless poise, Cohen transmits the full extent of his poetry, his irony, his all-round humanity, laughter and tears in one.<br /><br />To see some of these singer upstarts make convoluted suffering faces, launch their pathetic squeals in the patent effort to scream \"I\\'m a singer!,\" is a true pain. It\\'s the same feeling many of you probably had listening in to some horrendous operatic versions of simple songs such as Lennon\\'s \"Imagine.\" Nothing, simply nothing gets close to the simplicity and directness of the original. If there is a form of art that doesn\\'t need embellishments, it\\'s Cohen\\'s art. Embellishments cast it in the street looking like the tasteless make-up of sex for sale.<br /><br />In this Cohen\\'s tribute I found myself suffering and suffering through pitiful tributes and awful reinterpretations, all of them entirely lacking the original irony of the master and, if truth be told, several of these singers sounded as if they had been recruited at some asylum talent show. It\\'s Cohen doing a tribute to them by letting them sing his material, really, not the other way around: they may have been friends, or his daughter\\'s, he could have become very tender-hearted and in the mood for a gift. Too bad it didn\\'t stay in the family.<br /><br />Fortunately, but only at the very end, Cohen himself performed his majestic \"Tower of Song,\" but even that flower was spoiled by the totally incongruous background of the U2, all of them carrying the expression that bored kids have when they visit their poor grandpa at the nursing home.<br /><br />A sad show, really, and sadder if you truly love Cohen as I do.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e96743",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(sent) \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m train_texts]\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mrcParams\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.figsize\u001b[39m\u001b[38;5;124m'\u001b[39m:(\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m5\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.dpi\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m100\u001b[39m})\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sentences = [len(sent) for sent in train_texts]\n",
    "\n",
    "plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})\n",
    "plt.bar(range(1,2001), sentences, color = ['red'])\n",
    "plt.gca().set(title='No. of characters in each sentence', xlabel='Number of sentence', ylabel='Number of Characters in each sentence');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
